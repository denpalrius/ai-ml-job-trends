{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting AI and ML Job Trends with SARIMA\n",
    "\n",
    "At this stage, we perform Text Classification using the **DistilBERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/b_job_postings_with_labels.parquet\"\n",
    "job_postings = pd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,296,381 job postings loaded from data/b_job_postings_with_labels.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_processed_time</th>\n",
       "      <th>got_summary</th>\n",
       "      <th>got_ner</th>\n",
       "      <th>is_being_worked</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>skills_count</th>\n",
       "      <th>job_description</th>\n",
       "      <th>keyword_count</th>\n",
       "      <th>keyword_likelihood</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401008</th>\n",
       "      <td>2024-01-19 09:45:09.215838+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>summer camp instructor</td>\n",
       "      <td>phillip and patricia frost museum of science</td>\n",
       "      <td>miami, fl</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>highland park</td>\n",
       "      <td>united states</td>\n",
       "      <td>genealogist</td>\n",
       "      <td>mid senior</td>\n",
       "      <td>onsite</td>\n",
       "      <td>[science education, teaching, astronomy, aeron...</td>\n",
       "      <td>32</td>\n",
       "      <td>summer camp instructor genealogist phillip and...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520854</th>\n",
       "      <td>2024-01-19 09:45:09.215838+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>housekeeper (part time)</td>\n",
       "      <td>touchpoint support services</td>\n",
       "      <td>newburgh, in</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>indiana</td>\n",
       "      <td>united states</td>\n",
       "      <td>cleaner</td>\n",
       "      <td>mid senior</td>\n",
       "      <td>onsite</td>\n",
       "      <td>[cleaning, housekeeping, sweeping, scrubbing, ...</td>\n",
       "      <td>23</td>\n",
       "      <td>housekeeper (part time) cleaner touchpoint sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924911</th>\n",
       "      <td>2024-01-21 15:49:51.844651+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>food &amp; beverage manager - casual dining</td>\n",
       "      <td>full house resorts, inc</td>\n",
       "      <td>waukegan, il</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>illinois</td>\n",
       "      <td>united states</td>\n",
       "      <td>food-and-beverage controller</td>\n",
       "      <td>mid senior</td>\n",
       "      <td>onsite</td>\n",
       "      <td>[guest service, customer service, complaint re...</td>\n",
       "      <td>19</td>\n",
       "      <td>food &amp; beverage manager - casual dining food-a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100050</th>\n",
       "      <td>2024-01-19 18:02:51.789794+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>radiologic technologist</td>\n",
       "      <td>doylestown health</td>\n",
       "      <td>doylestown, pa</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>northampton</td>\n",
       "      <td>united states</td>\n",
       "      <td>radiologic technologist</td>\n",
       "      <td>mid senior</td>\n",
       "      <td>onsite</td>\n",
       "      <td>[xray imaging, dexa imaging, digital radiograp...</td>\n",
       "      <td>12</td>\n",
       "      <td>radiologic technologist radiologic technologis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353724</th>\n",
       "      <td>2024-01-19 09:45:09.215838+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>family practice-with ob physician - $275,000/y...</td>\n",
       "      <td>doccafe</td>\n",
       "      <td>rochester, ny</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>williamson</td>\n",
       "      <td>united states</td>\n",
       "      <td>family practitioner</td>\n",
       "      <td>mid senior</td>\n",
       "      <td>onsite</td>\n",
       "      <td>[physician, family practice, obstetrics, healt...</td>\n",
       "      <td>13</td>\n",
       "      <td>family practice-with ob physician - $275,000/y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  last_processed_time got_summary got_ner is_being_worked  \\\n",
       "401008  2024-01-19 09:45:09.215838+00           t       t               f   \n",
       "520854  2024-01-19 09:45:09.215838+00           t       t               f   \n",
       "924911  2024-01-21 15:49:51.844651+00           t       t               f   \n",
       "100050  2024-01-19 18:02:51.789794+00           t       t               f   \n",
       "353724  2024-01-19 09:45:09.215838+00           t       t               f   \n",
       "\n",
       "                                                job_title  \\\n",
       "401008                             summer camp instructor   \n",
       "520854                            housekeeper (part time)   \n",
       "924911            food & beverage manager - casual dining   \n",
       "100050                            radiologic technologist   \n",
       "353724  family practice-with ob physician - $275,000/y...   \n",
       "\n",
       "                                             company    job_location  \\\n",
       "401008  phillip and patricia frost museum of science       miami, fl   \n",
       "520854                   touchpoint support services    newburgh, in   \n",
       "924911                       full house resorts, inc    waukegan, il   \n",
       "100050                             doylestown health  doylestown, pa   \n",
       "353724                                       doccafe   rochester, ny   \n",
       "\n",
       "        first_seen    search_city search_country  \\\n",
       "401008  2024-01-13  highland park  united states   \n",
       "520854  2024-01-12        indiana  united states   \n",
       "924911  2024-01-16       illinois  united states   \n",
       "100050  2024-01-14    northampton  united states   \n",
       "353724  2024-01-13     williamson  united states   \n",
       "\n",
       "                     search_position   job_level job_type  \\\n",
       "401008                   genealogist  mid senior   onsite   \n",
       "520854                       cleaner  mid senior   onsite   \n",
       "924911  food-and-beverage controller  mid senior   onsite   \n",
       "100050       radiologic technologist  mid senior   onsite   \n",
       "353724           family practitioner  mid senior   onsite   \n",
       "\n",
       "                                               job_skills  skills_count  \\\n",
       "401008  [science education, teaching, astronomy, aeron...            32   \n",
       "520854  [cleaning, housekeeping, sweeping, scrubbing, ...            23   \n",
       "924911  [guest service, customer service, complaint re...            19   \n",
       "100050  [xray imaging, dexa imaging, digital radiograp...            12   \n",
       "353724  [physician, family practice, obstetrics, healt...            13   \n",
       "\n",
       "                                          job_description  keyword_count  \\\n",
       "401008  summer camp instructor genealogist phillip and...              1   \n",
       "520854  housekeeper (part time) cleaner touchpoint sup...              0   \n",
       "924911  food & beverage manager - casual dining food-a...              0   \n",
       "100050  radiologic technologist radiologic technologis...              0   \n",
       "353724  family practice-with ob physician - $275,000/y...              0   \n",
       "\n",
       "        keyword_likelihood  label  \n",
       "401008                   0      0  \n",
       "520854                   0      0  \n",
       "924911                   0      0  \n",
       "100050                   0      0  \n",
       "353724                   0      0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{len(job_postings):,} job postings loaded from {filename}\")\n",
    "job_postings.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job prediction using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer for DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# DistilBERT model for classification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1037104/1037104 [13:47<00:00, 1252.94 examples/s]\n",
      "Map: 100%|██████████| 259277/259277 [03:27<00:00, 1251.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1,037,104 samples\n",
      "Testing data: 259,277 samples\n"
     ]
    }
   ],
   "source": [
    "def create_tf_datasets():\n",
    "    # Tokenize the data\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"tf\",  # Ensure TF tensors\n",
    "        )\n",
    "\n",
    "    print(\"Tokenizing data and creating datasets...\")\n",
    "    # Convert data into a Dataset object\n",
    "    data = job_postings[[\"job_description\", \"label\"]]\n",
    "    data = data.rename(columns={\"job_description\": \"text\"})\n",
    "    dataset = Dataset.from_dict(data)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "    train_data = train_test_split[\"train\"]\n",
    "    test_data = train_test_split[\"test\"]\n",
    "\n",
    "    # Prepare training and test datasets\n",
    "    train_encoded = train_data.map(tokenize_function, batched=True)\n",
    "    test_encoded = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "    print(f\"Training data: {len(train_encoded):,} samples\")\n",
    "    print(f\"Testing data: {len(test_encoded):,} samples\")\n",
    "\n",
    "    print(\"Creating TensorFlow datasets...\")\n",
    "    # Convert labels to tensors\n",
    "    train_labels = tf.convert_to_tensor(train_data[\"label\"], dtype=tf.int32)\n",
    "    test_labels = tf.convert_to_tensor(test_data[\"label\"], dtype=tf.int32)\n",
    "\n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": train_encoded[\"input_ids\"],\n",
    "                \"attention_mask\": train_encoded[\"attention_mask\"]\n",
    "            },\n",
    "            train_labels\n",
    "        )\n",
    "    ).shuffle(100).batch(8)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": test_encoded[\"input_ids\"],\n",
    "                \"attention_mask\": test_encoded[\"attention_mask\"]\n",
    "            },\n",
    "            test_labels\n",
    "        )\n",
    "    ).batch(16)\n",
    "    \n",
    "    def save_tf_datasets(train_ds, test_ds, save_dir='./data/tf_datasets'):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Save datasets\n",
    "        tf.data.experimental.save(train_ds, os.path.join(save_dir, 'train'))\n",
    "        tf.data.experimental.save(test_ds, os.path.join(save_dir, 'test'))\n",
    "        \n",
    "        print(f\"Datasets saved to {save_dir}\")\n",
    "\n",
    "    save_tf_datasets(train_dataset, test_dataset)\n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = create_tf_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tf_datasets(train_ds, test_ds, save_dir='./data/tf_datasets'):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Save datasets\n",
    "        tf.data.experimental.save(train_ds, os.path.join(save_dir, 'train'))\n",
    "        tf.data.experimental.save(test_ds, os.path.join(save_dir, 'test'))\n",
    "        \n",
    "        print(f\"Datasets saved to {save_dir}\")\n",
    "\n",
    "save_tf_datasets(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_datasets(job_postings=None, tokenizer=None, load_dir=\"./data/tf_datasets\"):\n",
    "    \"\"\"Load or create TensorFlow datasets\"\"\"\n",
    "    try:\n",
    "        # Try loading saved datasets\n",
    "        train_dataset = tf.data.experimental.load(\n",
    "            os.path.join(load_dir, \"train\"), element_spec=train_dataset.element_spec\n",
    "        )\n",
    "        test_dataset = tf.data.experimental.load(\n",
    "            os.path.join(load_dir, \"test\"), element_spec=test_dataset.element_spec\n",
    "        )\n",
    "    except (FileNotFoundError, NameError):\n",
    "        # Create new datasets if loading fails\n",
    "        if job_postings is None or tokenizer is None:\n",
    "            raise ValueError(\n",
    "                \"job_postings and tokenizer required when datasets not found\"\n",
    "            )\n",
    "\n",
    "        print(\"Creating new datasets...\")\n",
    "        train_dataset, test_dataset = create_tf_datasets(job_postings, tokenizer)\n",
    "\n",
    "        # Save datasets\n",
    "        os.makedirs(load_dir, exist_ok=True)\n",
    "        tf.data.experimental.save(train_dataset, os.path.join(load_dir, \"train\"))\n",
    "        tf.data.experimental.save(test_dataset, os.path.join(load_dir, \"test\"))\n",
    "        print(f\"Datasets saved to {load_dir}\")\n",
    "\n",
    "    # Reapply dataset operations\n",
    "    train_dataset = train_dataset.shuffle(100).batch(8)\n",
    "    test_dataset = test_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"./results/tf_checkpoints/model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_format=\"keras\",\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", update_freq=\"batch\"),\n",
    "]\n",
    "\n",
    "# Model training\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    validation_data=test_dataset,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "results = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a sample job description\n",
    "sample_job = \"Looking for a data scientist skilled in machine learning and data analysis.\"\n",
    "encoded_input = tokenizer(sample_job, return_tensors=\"tf\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "output = model(encoded_input)\n",
    "prediction = tf.argmax(output.logits, axis=-1).numpy()[0]\n",
    "\n",
    "print(f\"Predicted label: {'AI skills required' if prediction == 1 else 'No AI skills required'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
